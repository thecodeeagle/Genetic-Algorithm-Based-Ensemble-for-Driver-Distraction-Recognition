{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GAEnsemble2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thecodeeagle/Genetic-Algorithm-Based-Ensemble-for-Driver-Distraction-Recognition/blob/main/GAEnsemble2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1306DmBm_8z0"
      },
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjvOSTI-2rUl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG5KvGveoy9z"
      },
      "source": [
        "!pip install -q --upgrade ipython\n",
        "!pip install -q --upgrade ipykernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woMRy_MppWFh"
      },
      "source": [
        "def weighted_ensemble(weights, models, inputs):\n",
        "    # Assigning empty array to store 2D array of model predictions\n",
        "    predictions = []\n",
        "    predictionsSum = 0\n",
        "  \n",
        "    # Loop through all models\n",
        "\n",
        "    for i in range(len(models)):\n",
        "       labels = models[i].predict(inputs)\n",
        "\n",
        "       predictions.append(labels)\n",
        "       predictionsSum += (labels*weights[i])\n",
        "      \n",
        "      \n",
        "\n",
        "    # Sum of weighted predictions\n",
        "    predictions[i] = [x * weights[i] for x in predictions[i]]\n",
        "                      \n",
        "    return predictionsSum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMW32Hocpnjy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def cal_pop_fitness(fitness_func, pop):\n",
        "    \n",
        "    fitness = fitness_func(pop)\n",
        "    return fitness\n",
        "\n",
        "\n",
        "def select_mating_pool(pop, fitness, num_parents):\n",
        "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next\n",
        "    # #generation.\n",
        "    \n",
        "    parents = np.empty((num_parents, pop.shape[1]))\n",
        "    for parent_num in range(num_parents):\n",
        "        max_fitness_idx = np.where(fitness == np.min(fitness))\n",
        "        max_fitness_idx = max_fitness_idx[0][0]\n",
        "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
        "        fitness[max_fitness_idx] = -99999999999\n",
        "        print(parents.shape)\n",
        "    return parents\n",
        "\n",
        "\n",
        "def crossover(parents, offspring_size):\n",
        "    offspring = np.empty(offspring_size)\n",
        "    # The point at which crossover takes place between two parents. Usually it is at the center.\n",
        "    crossover_point = np.uint8(offspring_size[1]/2)\n",
        "\n",
        "    for k in range(offspring_size[0]):\n",
        "        # Index of the first parent to mate.\n",
        "        parent1_idx = k % parents.shape[0]\n",
        "        # Index of the second parent to mate.\n",
        "        parent2_idx = (k+1) % parents.shape[0]\n",
        "        # The new offspring will have its first half of its genes taken from the first parent.\n",
        "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
        "        # The new offspring will have its second half of its genes taken from the second parent.\n",
        "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
        "    return offspring\n",
        "\n",
        "\n",
        "def mutation(offspring_crossover):\n",
        "    # Mutation changes a single gene in each offspring randomly.\n",
        "    for idx in range(offspring_crossover.shape[0]):\n",
        "        # The random value to be added to the gene.\n",
        "        random_value = np.random.uniform(0, 1, 1)\n",
        "        offspring_crossover[idx-1, offspring_crossover.shape[0]-1] = \\\n",
        "            offspring_crossover[idx-1, offspring_crossover.shape[0]-1] + random_value\n",
        "    return offspring_crossover"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL4mv6UcpWKq"
      },
      "source": [
        "def ensemble_fitness(weights, models, inputs, targets, value):\n",
        "    import numpy as np\n",
        "    import sklearn\n",
        "    from sklearn import linear_model\n",
        "    from sklearn import metrics\n",
        "    \n",
        "\n",
        "    fitness = []\n",
        "\n",
        "    # Normalise weights\n",
        "    weights = sklearn.preprocessing.normalize(weights, axis=1, norm='l1')\n",
        "\n",
        "    for i in range(len(weights)):\n",
        "        predictionsSum = weighted_ensemble(weights[i-1], models, inputs)\n",
        "\n",
        "        # Calculating bias and variance for use in error if selected\n",
        "        bias = (np.mean(predictionsSum)-np.mean(targets))**2\n",
        "        variance = np.var(predictionsSum-targets)\n",
        "\n",
        "        # Setting output fitness value\n",
        "        if value == \"mse\":\n",
        "            ensembleFit = metrics.mean_squared_error(predictionsSum, targets)\n",
        "        elif value == \"mae\":\n",
        "            ensembleFit = metrics.mean_absolute_error(predictionsSum, targets)\n",
        "        elif value == \"bias\":\n",
        "            ensembleFit = bias\n",
        "        elif value == \"variance\":\n",
        "            ensembleFit = variance\n",
        "        elif value == \"error\":\n",
        "            ensembleFit = bias+variance\n",
        "        elif value == \"log_loss\":\n",
        "            ensembleFit = metrics.log_loss()\n",
        "        else:\n",
        "            # If error with input then set it to mse as default\n",
        "            ensembleFit = metrics.mean_squared_error(predictionsSum, targets)\n",
        "\n",
        "        fitness.append(ensembleFit)\n",
        "\n",
        "    # Returning fitness value to minimise\n",
        "    return fitness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SJL0P4dPGta",
        "outputId": "2459d52f-b947-4083-cdac-399de3bed90b"
      },
      "source": [
        "%cd drive/My Drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVQMs8l6w2qu"
      },
      "source": [
        "from tensorflow import keras\n",
        "model1 = keras.models.load_model('new_ensemble_effnet_2')\n",
        "model2 = keras.models.load_model('new_vanillaCNN')\n",
        "model3 = keras.models.load_model('new_alexnet')\n",
        "model4 = keras.models.load_model('newd_inceptionv3')\n",
        "model5 = keras.models.load_model('new_vgg')\n",
        "model6 = keras.models.load_model('new_densenet3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifAKzOrZcLQO"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_9KXGljoiSr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as pyplot\n",
        "from sklearn import linear_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW6FE_8X4_p4"
      },
      "source": [
        "loaded = np.load(\"newdriver.npz\")\n",
        "test_images = loaded[\"test_images\"]\n",
        "test_labels = loaded[\"test_labels\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZtUd6FmIwSy"
      },
      "source": [
        "import tensorflow as tf\n",
        "test = tf.keras.utils.to_categorical(test_labels, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8WTVtAHZ6gP"
      },
      "source": [
        "test_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO5z63Qx3VhE"
      },
      "source": [
        "models = []\n",
        "models.append(model1)\n",
        "models.append(model2)\n",
        "models.append(model3)\n",
        "models.append(model4)\n",
        "models.append(model5)\n",
        "models.append(model6)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur_l7xGBcuTi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YpDxa8GoiS1"
      },
      "source": [
        "# Create objective function\n",
        "objective_function = lambda w: ensemble_fitness(w, models, test_images, test, 'mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rZpOArUoiS3",
        "outputId": "1eea5bcd-d249-461b-b13e-2e0aaa4bc0f6"
      },
      "source": [
        "# Set Genetic Algorithm parameters\n",
        "sol_per_pop = 6\n",
        "num_parents_mating = 3\n",
        "# Defining population size\n",
        "pop_size = (sol_per_pop, len(models))\n",
        "print(pop_size)\n",
        "# Creating the initial population\n",
        "\n",
        "new_population = np.random.uniform(low=0, high=1, size=pop_size)\n",
        "print(new_population)\n",
        "#new_population = np.load(\"drive/My Drive/np2.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 3)\n",
            "[[0.75541172 0.98754322 0.49410283]\n",
            " [0.09499213 0.24923789 0.74603505]\n",
            " [0.65679673 0.38242468 0.83737382]\n",
            " [0.08425166 0.09971454 0.77465574]\n",
            " [0.77971041 0.19239526 0.09672093]\n",
            " [0.19331701 0.34398595 0.25154385]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIBNVBpJu7Yi"
      },
      "source": [
        "new_population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KdkmEcjdU-X"
      },
      "source": [
        "for generation in range(50):\n",
        "    print(\"Generation: \", generation)\n",
        "    # Measuring the fitness of each chromosome in the population\n",
        "    fitness = cal_pop_fitness(objective_function, new_population)\n",
        "\n",
        "    # Selecting the best parents in the population for mating\n",
        "    parents = select_mating_pool(new_population, fitness, num_parents_mating)\n",
        "\n",
        "    # Generating next generation using crossover\n",
        "    offspring_crossover = crossover(parents, offspring_size=(parents.shape[0], len(models)))\n",
        "\n",
        "    # Adding some variations to the offspring using mutation\n",
        "    offspring_mutation = mutation(offspring_crossover)\n",
        "\n",
        "    # Creating the new population based on the parents and offspring\n",
        "    new_population[0:parents.shape[0], :] = parents\n",
        "    new_population[parents.shape[0]:, :] = offspring_mutation\n",
        "\n",
        "    # The best result in the current iteration\n",
        "    #print(\"NOTHING\")\n",
        "    print(\"FITNESS VALUE:\", fitness)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LnzW0m6fqABN"
      },
      "source": [
        "new_population = new_population['arr_0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuc0kIhmoiS8"
      },
      "source": [
        "# Get the best solution after all generations\n",
        "fitness = cal_pop_fitness(objective_function, new_population)\n",
        "# Return the index of that solution and corresponding best fitness\n",
        "best_match_idx = np.where(fitness == np.min(fitness))\n",
        "best_match = list(best_match_idx[0])\n",
        "print(best_match)\n",
        "print(fitness)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u9B95aPkoiS_"
      },
      "source": [
        "# Return weights\n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "weights = new_population[int(best_match[0])]\n",
        "# Display optimised network ensemble accuracy details\n",
        "results = weighted_ensemble(weights, models, test_images)\n",
        "pyplot.scatter(results, test_labels)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZdzgBnXLoiTC"
      },
      "source": [
        "new_population"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RZf9DXToiTE"
      },
      "source": [
        "weights = new_population[int(best_match[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtnGLPFjoiTG"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3rik1wAp5LqK"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tasfZ4pnoiTI"
      },
      "source": [
        "i=0\n",
        "sum = 0.00\n",
        "while(i<6):\n",
        "  sum+= (models[i].predict(test_images))*weights[i]\n",
        "  i+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD8foVVOoiTK"
      },
      "source": [
        "final = np.argmax(sum/np.sum(weights), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWO54inYkuuc"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(final, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W2hGPfwNoiTN"
      },
      "source": [
        "tolerance = 1e-10\n",
        "accuracy = (np.abs(y_pred - test) < tolerance ).all(axis=(0,2)).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K_vyJUa-GlIp"
      },
      "source": [
        "np.savez(\"drive/My Drive/ensemble\",new_population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "79qeKVSAnUY0"
      },
      "source": [
        "loaded = np.load['drive/My Drive/ensemble']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZi9-LNfGoTY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(40, 40)) \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFXibcE-Gzxr"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm_plot_labels = ['Safe Driving','Text Right','Phone Right', 'Text Left', 'Phone_Left','Adjust Radio', 'Drinking', 'Reaching Behind', 'Hair or Makeup', 'Talking to Passenger']\n",
        "cm= confusion_matrix(y_true = test_labels, y_pred = final)\n",
        "\n",
        "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix', normalize = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}